{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe02ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#carregando a base Iris\n",
    "df = pd.read_csv('datasets/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48f7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos fazer a mudança de tipo da coluna alvo usando LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['Species']) #ajusta a função aos dados\n",
    "df['class'] = le.transform(df['Species']) #aplica a função aos dados e atribui à coluna alvo\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb40c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checando o balance das classes \n",
    "df['Species'].value_counts()\n",
    "#(totalmente balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507df331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['Id','class','Species']), df['class'], test_size=0.33, random_state=15, stratify=df['class'])\n",
    "#neste caso o stratify não tem efeito por ser base já balanceada por padrão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2097b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd5f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cd51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vamos usar uma árvore de decisão simples\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=10) #inicializa o modelo com valores default, ainda não treinado\n",
    "dt_clf.fit(X_train, y_train) #ajusta o modelo com os dados de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a387f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicao no conjunto de teste\n",
    "y_pred = dt_clf.predict(X_test) #executa a predição para os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a88e62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfa21a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdf741e",
   "metadata": {},
   "source": [
    "Relembrando: <img src='img/metrics_theory.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b91fdd4",
   "metadata": {},
   "source": [
    "* **Acurácia**: Percentual de acertos gerais (tanto positivos quanto negativos) do classificador para os dados amostrados\n",
    "* **Precisão**: Dentre todas as amostras que o classificador rotulou como positivas, quantas realmente eram positivas (*Quando um classificador é altamente preciso, ele tem maior confiabilidade ao rotular como positiva uma amostra. Quando ele diz que é de uma classe, é porque é :D*)\n",
    "* **Recall**: O recall ou sensibilidade ou revocação é a capacidade do classificador de encontrar todas as amostras positivas, ou seja, dentre todas as amostras que eram positivas, quantas o classificador conseguiu identificar (*Quando um classificador tem alta sensibilidade, o número de falsos negativos é baixo. Quando ele diz que não é, é porque não é :D*)\n",
    "* **F1-Score**: A medida F é uma média harmônica ponderada entre precisão e recall, que atinge seu melhor valor em 1 e o pior em 0. Quando se usa F1, se considera a precisão e o recall com a mesma importância.\n",
    "* **Suporte**: Indica o número de amostras para cada classe testada\n",
    "* **Especificidade**: Especificidade é a capacidade do classificador de encontrar todas as amostras da classe negativa (complemento da sensibilidade para problemas com 2 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a779a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'criterion': ['gini', 'entropy', 'log_loss'], \n",
    "              'splitter': ['best', 'random'],\n",
    "              'max_depth': range(2,6), \n",
    "              'max_features': [2,3,4]} \n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, scoring='accuracy', cv=5, n_jobs=-1, verbose = 3) #verbose indica a quantidade de detalhamento das mensagens apresentadas no fit\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b555244",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gs = grid.predict(X_test) #ou grid.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b647e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_true=y_test, y_pred=y_pred_gs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320eccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = metrics.confusion_matrix(y_test,y_pred_gs)\n",
    "print(cm)\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=grid.best_estimator_.classes_)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4545d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree.plot_tree(grid.best_estimator_, feature_names=['sepal_L','sepal_W','petal_L','petal_W'],class_names=['setosa','versicolor','virginica'],\n",
    "               filled=True, rounded=True, fontsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf87d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "#import numpy as np\n",
    "scores = cross_val_score(grid.best_estimator_, X_train, y_train, cv=10, scoring='accuracy') #para comparar modelos\n",
    "#print(np.mean(scores))#média do CV\n",
    "#print(np.std(scores)) #crossvalidation\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86138c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se quiser salvar tudo para análise posterior detalhada\n",
    "dfgs = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgs.loc[dfgs['rank_test_score'] == 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgs.to_csv('./resultadogridsearchdt.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385c0a87",
   "metadata": {},
   "source": [
    "### Vamos usar a ideia do CV para comparar modelos com seus parâmetros default. O que apresentar melhor média de métrica e desvio padrão, escolhemos para gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "def evaluate_model(model, feature_vector, target):\n",
    "    X_train_limited, X_validation, y_train_limited, y_validation = train_test_split(feature_vector, target, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train_limited, y_train_limited)\n",
    "    print(\"Accuracy full validation set: %0.2f\" % model.score(X_validation, y_validation))\n",
    "    score = cross_val_score(model, feature_vector, target, cv=10, scoring='accuracy', n_jobs=-1)\n",
    "    print(\"Mean Accuracy CV: %0.2f (+/- %0.2f)\" % (score.mean(), score.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier()\n",
    "evaluate_model(knn_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63332413",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(dt_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d5d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "cb_model = GradientBoostingClassifier()\n",
    "evaluate_model(cb_model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "evaluate_model(rf_clf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0929965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
